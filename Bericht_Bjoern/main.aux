\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\catcode `"\active 
\abx@aux@sortscheme{none}
\abx@aux@sortnamekeyscheme{global}
\@writefile{toc}{\boolfalse {citerequest}\boolfalse {citetracker}\boolfalse {pagetracker}\boolfalse {backtracker}\relax }
\@writefile{lof}{\boolfalse {citerequest}\boolfalse {citetracker}\boolfalse {pagetracker}\boolfalse {backtracker}\relax }
\@writefile{lot}{\boolfalse {citerequest}\boolfalse {citetracker}\boolfalse {pagetracker}\boolfalse {backtracker}\relax }
\select@language{ngerman}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\select@language{ngerman}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\select@language{ngerman}}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\select@language{ngerman}}
\abx@aux@cite{OCT}
\abx@aux@cite{Dataset}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {1}Einleitung}{1}{section.1}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {2}Analysierter Datensatz}{2}{section.2}}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Zusammensetzung des untersuchten Datensatzes aufgeteilt nach den im Datensatz vorhandenen Krankheiten, CNV, DME und DRUSEN, und Aufnahmen, die keine dieser Krankheiten aufweisen und mit NORMAL gekennzeichnet werden.\relax }}{2}{table.caption.2}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{tab:datacomp}{{1}{2}{Zusammensetzung des untersuchten Datensatzes aufgeteilt nach den im Datensatz vorhandenen Krankheiten, CNV, DME und DRUSEN, und Aufnahmen, die keine dieser Krankheiten aufweisen und mit NORMAL gekennzeichnet werden.\relax }{table.caption.2}{}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {NORMAL}}}{2}{figure.1}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {CNV }}}{2}{figure.1}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {subfigure}{\numberline{(c)}{\ignorespaces {DME }}}{2}{figure.1}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {subfigure}{\numberline{(d)}{\ignorespaces {DRUSEN }}}{2}{figure.1}}
\newlabel{fig:NORMexa}{{1(a)}{2}{Subfigure 1(a)}{subfigure.1.1}{}}
\newlabel{sub@fig:NORMexa}{{(a)}{2}{Subfigure 1(a)\relax }{subfigure.1.1}{}}
\newlabel{fig:CNVexa}{{1(b)}{2}{Subfigure 1(b)}{subfigure.1.2}{}}
\newlabel{sub@fig:CNVexa}{{(b)}{2}{Subfigure 1(b)\relax }{subfigure.1.2}{}}
\newlabel{fig:DMEexa}{{1(c)}{2}{Subfigure 1(c)}{subfigure.1.3}{}}
\newlabel{sub@fig:DMEexa}{{(c)}{2}{Subfigure 1(c)\relax }{subfigure.1.3}{}}
\newlabel{fig:DRUSENexa}{{1(d)}{2}{Subfigure 1(d)}{subfigure.1.4}{}}
\newlabel{sub@fig:DRUSENexa}{{(d)}{2}{Subfigure 1(d)\relax }{subfigure.1.4}{}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces OCT Aufnahmen der Retina, die beispielhaft eine Aufnahme jeder untersuchten Klasse im Datensatz zeigen. Dabei zeigt Abbildung \ref  {fig:NORMexa} eine OCT Aufnahme der Klasse NORMAL, die von keiner der Krankheiten, CNV, DME und DRUSEN, aufweist, welche in den Abbildungen \ref  {fig:CNVexa}, \ref  {fig:DMEexa} respektive \ref  {fig:DRUSENexa} dargestellt sind.\relax }}{2}{figure.1}}
\newlabel{fig:example}{{1}{2}{OCT Aufnahmen der Retina, die beispielhaft eine Aufnahme jeder untersuchten Klasse im Datensatz zeigen. Dabei zeigt Abbildung \ref {fig:NORMexa} eine OCT Aufnahme der Klasse NORMAL, die von keiner der Krankheiten, CNV, DME und DRUSEN, aufweist, welche in den Abbildungen \ref {fig:CNVexa}, \ref {fig:DMEexa} respektive \ref {fig:DRUSENexa} dargestellt sind.\relax }{figure.1}{}}
\abx@aux@cite{MNIST}
\abx@aux@cite{Adam}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {3}Methoden zur Klassifizierung von OCT Aufnahmen der Retina}{3}{section.3}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Tiefes faltendes neuronales Netz (CNN)}{3}{subsection.3.1}}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces Schematische Darstellung der Referenzstruktur des CNN. Die Werte in den unteren Zeilen repr\IeC {\"a}sentieren die Neuronenstruktur am Ausgang jeder Lage. Im Falle einer Dropout Lage stellt der Wert die festgelegte Rate dar. F\IeC {\"u}r die Conv2D Lagen werden zudem die Anzahl an verwendeten Kernels sowie ihrer Dimension und die Schrittweite angegeben. F\IeC {\"u}r die Pooling Lagen werden die definierten Dimensionen der verwendeten Fenster angegeben.\relax }}{4}{table.caption.3}}
\newlabel{fig:refstrukt}{{2}{4}{Schematische Darstellung der Referenzstruktur des CNN. Die Werte in den unteren Zeilen repr채sentieren die Neuronenstruktur am Ausgang jeder Lage. Im Falle einer Dropout Lage stellt der Wert die festgelegte Rate dar. F체r die Conv2D Lagen werden zudem die Anzahl an verwendeten Kernels sowie ihrer Dimension und die Schrittweite angegeben. F체r die Pooling Lagen werden die definierten Dimensionen der verwendeten Fenster angegeben.\relax }{table.caption.3}{}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {Genauigkeit}}}{5}{figure.3}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {Verlustfunktion}}}{5}{figure.3}}
\newlabel{fig:refstrukacc}{{3(a)}{5}{Subfigure 3(a)}{subfigure.3.1}{}}
\newlabel{sub@fig:refstrukacc}{{(a)}{5}{Subfigure 3(a)\relax }{subfigure.3.1}{}}
\newlabel{fig:refstrukloss}{{3(b)}{5}{Subfigure 3(b)}{subfigure.3.2}{}}
\newlabel{sub@fig:refstrukloss}{{(b)}{5}{Subfigure 3(b)\relax }{subfigure.3.2}{}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Genauigkeit \ref  {fig:refstrukacc} und Wert der Verlustfunktion \ref  {fig:refstrukloss} nach jeder Epoche des Trainings bei Propagation des Trainings- und Validierungsdatensatzes durch das CNN mit der Referenzstruktur. \relax }}{5}{figure.3}}
\newlabel{fig:refstruk}{{3}{5}{Genauigkeit \ref {fig:refstrukacc} und Wert der Verlustfunktion \ref {fig:refstrukloss} nach jeder Epoche des Trainings bei Propagation des Trainings- und Validierungsdatensatzes durch das CNN mit der Referenzstruktur. \relax }{figure.3}{}}
\newlabel{fig:confmatun}{{4(a)}{6}{Subfigure 4(a)}{subfigure.4.1}{}}
\newlabel{sub@fig:confmatun}{{(a)}{6}{Subfigure 4(a)\relax }{subfigure.4.1}{}}
\newlabel{fig:confmatweight}{{4(b)}{6}{Subfigure 4(b)}{subfigure.4.2}{}}
\newlabel{sub@fig:confmatweight}{{(b)}{6}{Subfigure 4(b)\relax }{subfigure.4.2}{}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Verwirrungsmatrizen nach dem Training ohne Gewichtung des Datensatzes in Abbildung \ref  {fig:confmatun} und mit verwendeter Gewichtung in Abbildung \ref  {fig:confmatweight}.\relax }}{6}{figure.4}}
\newlabel{fig:confmat}{{4}{6}{Verwirrungsmatrizen nach dem Training ohne Gewichtung des Datensatzes in Abbildung \ref {fig:confmatun} und mit verwendeter Gewichtung in Abbildung \ref {fig:confmatweight}.\relax }{figure.4}{}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {Ungewichteter Datensatz}}}{6}{figure.4}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {Gewichteter Datensatz}}}{6}{figure.4}}
\newlabel{fig:confmatrelu}{{5(a)}{7}{Subfigure 5(a)}{subfigure.5.1}{}}
\newlabel{sub@fig:confmatrelu}{{(a)}{7}{Subfigure 5(a)\relax }{subfigure.5.1}{}}
\newlabel{fig:confmatsmaller}{{5(b)}{7}{Subfigure 5(b)}{subfigure.5.2}{}}
\newlabel{sub@fig:confmatsmaller}{{(b)}{7}{Subfigure 5(b)\relax }{subfigure.5.2}{}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Verwirrungsmatrizen bei Verwendung des gewichteten Datensatzes des CNN mit der Referenzstruktur mit relu als Aktivierungsfunktion der versteckten Lagen \ref  {fig:confmatrelu} und ver\IeC {\"a}nderter Struktur der dichten Lagen \ref  {fig:confmatsmaller}.\relax }}{7}{figure.5}}
\newlabel{fig:confmatrelusmall}{{5}{7}{Verwirrungsmatrizen bei Verwendung des gewichteten Datensatzes des CNN mit der Referenzstruktur mit relu als Aktivierungsfunktion der versteckten Lagen \ref {fig:confmatrelu} und ver채nderter Struktur der dichten Lagen \ref {fig:confmatsmaller}.\relax }{figure.5}{}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {relu als Aktivierungsfunktion}}}{7}{figure.5}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {Ver\IeC {\"a}nderte Struktur des CNN}}}{7}{figure.5}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {Genauigkeit}}}{7}{figure.6}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {Verlustfunktion}}}{7}{figure.6}}
\newlabel{fig:accsmaller}{{6(a)}{7}{Subfigure 6(a)}{subfigure.6.1}{}}
\newlabel{sub@fig:accsmaller}{{(a)}{7}{Subfigure 6(a)\relax }{subfigure.6.1}{}}
\newlabel{fig:losssmaller}{{6(b)}{7}{Subfigure 6(b)}{subfigure.6.2}{}}
\newlabel{sub@fig:losssmaller}{{(b)}{7}{Subfigure 6(b)\relax }{subfigure.6.2}{}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Genauigkeit \ref  {fig:accsmaller} und Wert der Verlustfunktion \ref  {fig:losssmaller} nach jeder Epoche des Trainings bei Propagation des Trainingsdatensatzes und Validierungsdatensatzes durch das CNN mit der angepassten Struktur der dichten Lagen.\relax }}{7}{figure.6}}
\newlabel{fig:smallerperf}{{6}{7}{Genauigkeit \ref {fig:accsmaller} und Wert der Verlustfunktion \ref {fig:losssmaller} nach jeder Epoche des Trainings bei Propagation des Trainingsdatensatzes und Validierungsdatensatzes durch das CNN mit der angepassten Struktur der dichten Lagen.\relax }{figure.6}{}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {NORMAL}}}{8}{figure.7}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {CNV}}}{8}{figure.7}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {subfigure}{\numberline{(c)}{\ignorespaces {DME}}}{8}{figure.7}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {subfigure}{\numberline{(d)}{\ignorespaces {DRUSEN}}}{8}{figure.7}}
\newlabel{fig:probnorm}{{7(a)}{8}{Subfigure 7(a)}{subfigure.7.1}{}}
\newlabel{sub@fig:probnorm}{{(a)}{8}{Subfigure 7(a)\relax }{subfigure.7.1}{}}
\newlabel{fig:probcnv}{{7(b)}{8}{Subfigure 7(b)}{subfigure.7.2}{}}
\newlabel{sub@fig:probcnv}{{(b)}{8}{Subfigure 7(b)\relax }{subfigure.7.2}{}}
\newlabel{fig:probdme}{{7(c)}{8}{Subfigure 7(c)}{subfigure.7.3}{}}
\newlabel{sub@fig:probdme}{{(c)}{8}{Subfigure 7(c)\relax }{subfigure.7.3}{}}
\newlabel{fig:probdrusen}{{7(d)}{8}{Subfigure 7(d)}{subfigure.7.4}{}}
\newlabel{sub@fig:probdrusen}{{(d)}{8}{Subfigure 7(d)\relax }{subfigure.7.4}{}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Verteilung der von dem CNN vorhergesagten Wahrscheinlichkeiten f\IeC {\"u}r die Aufnahmen innerhalb einer Klasse X und f\IeC {\"u}r die Aufnahmen, die nicht dieser Klasse angeh\IeC {\"o}ren (!=X), der Klasse X anzugeh\IeC {\"o}ren. Die Abbildungen \ref  {fig:probnorm}, \ref  {fig:probcnv}, \ref  {fig:probdme} und \ref  {fig:probdrusen} zeigen dies f\IeC {\"u}r die Klassen NORMAL, CNV, DME respektive DRUSEN. \relax }}{8}{figure.7}}
\newlabel{fig:probCNN}{{7}{8}{Verteilung der von dem CNN vorhergesagten Wahrscheinlichkeiten f체r die Aufnahmen innerhalb einer Klasse X und f체r die Aufnahmen, die nicht dieser Klasse angeh철ren (!=X), der Klasse X anzugeh철ren. Die Abbildungen \ref {fig:probnorm}, \ref {fig:probcnv}, \ref {fig:probdme} und \ref {fig:probdrusen} zeigen dies f체r die Klassen NORMAL, CNV, DME respektive DRUSEN. \relax }{figure.7}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Tiefes flaches neuronales Netz (DNN)}{9}{subsection.3.2}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {Modell 0}}}{10}{figure.8}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {Modell 1}}}{10}{figure.8}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {subfigure}{\numberline{(c)}{\ignorespaces {Modell 2}}}{10}{figure.8}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {subfigure}{\numberline{(d)}{\ignorespaces {Modell 3}}}{10}{figure.8}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {subfigure}{\numberline{(e)}{\ignorespaces {Modell 4}}}{10}{figure.8}}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\contentsline {table}{\numberline {3}{\ignorespaces Getestete Grundstrukturen des DNN. Die Anzahl an Neuronen in der $i$-ten versteckten Lage und die Dropout Rate in der $i$-ten Dropout Lage sind durch das $i$-te Element der entsprechenden List dargestellt. Auf die $i$-te versteckte Lage folgt dabei die $i$-te Dropout Lage.\relax }}{10}{table.caption.4}}
\newlabel{tab:DNNstruk}{{3}{10}{Getestete Grundstrukturen des DNN. Die Anzahl an Neuronen in der $i$-ten versteckten Lage und die Dropout Rate in der $i$-ten Dropout Lage sind durch das $i$-te Element der entsprechenden List dargestellt. Auf die $i$-te versteckte Lage folgt dabei die $i$-te Dropout Lage.\relax }{table.caption.4}{}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces Erhaltene Genauigkeiten des DNN nach 150 Epochen f\IeC {\"u}r die verschiedenen Konfigurationen der einzelnen Modelle als Funktion der Batch Gr\IeC {\"o}{\ss }e.\relax }}{11}{figure.8}}
\newlabel{fig:accgrid}{{8}{11}{Erhaltene Genauigkeiten des DNN nach 150 Epochen f체r die verschiedenen Konfigurationen der einzelnen Modelle als Funktion der Batch Gr철{\ss }e.\relax }{figure.8}{}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {Verlustfunktion}}}{11}{figure.9}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {Verwirrungsmatrix}}}{11}{figure.9}}
\newlabel{fig:DNNloss}{{9(a)}{11}{Subfigure 9(a)}{subfigure.9.1}{}}
\newlabel{sub@fig:DNNloss}{{(a)}{11}{Subfigure 9(a)\relax }{subfigure.9.1}{}}
\newlabel{fig:confmatDNN}{{9(b)}{11}{Subfigure 9(b)}{subfigure.9.2}{}}
\newlabel{sub@fig:confmatDNN}{{(b)}{11}{Subfigure 9(b)\relax }{subfigure.9.2}{}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces Wert der Verlustfunktion nach jeder Epoche \ref  {fig:DNNloss} bei Propagation des Trainings- und Validierungsdatensatzes und Verwirrungsmatrix \ref  {fig:confmatDNN} bei Propagation des Testdatensatzes f\IeC {\"u}r die gew\IeC {\"a}hlte DNN Struktur. \relax }}{11}{figure.9}}
\newlabel{fig:DNN}{{9}{11}{Wert der Verlustfunktion nach jeder Epoche \ref {fig:DNNloss} bei Propagation des Trainings- und Validierungsdatensatzes und Verwirrungsmatrix \ref {fig:confmatDNN} bei Propagation des Testdatensatzes f체r die gew채hlte DNN Struktur. \relax }{figure.9}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {4}Zusammenfassung und Schlussfolgerungen}{12}{section.4}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {5}Literatur}{13}{section.5}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {A}Zusatzliche Abbildungen und Ergebnisse bei Verwendung des CNN}{14}{appendix.A}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {Ungewichteter Datensatz}}}{14}{figure.10}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {Gewichteter Datensatz}}}{14}{figure.10}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {subfigure}{\numberline{(c)}{\ignorespaces {relu statt elu als Aktivierungsfunktion}}}{14}{figure.10}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {subfigure}{\numberline{(d)}{\ignorespaces {Verkleinerte Dimensionen der dichten Lagen}}}{14}{figure.10}}
\newlabel{fig:accequal}{{10(a)}{14}{Subfigure 10(a)}{subfigure.10.1}{}}
\newlabel{sub@fig:accequal}{{(a)}{14}{Subfigure 10(a)\relax }{subfigure.10.1}{}}
\newlabel{fig:accnormal}{{10(b)}{14}{Subfigure 10(b)}{subfigure.10.2}{}}
\newlabel{sub@fig:accnormal}{{(b)}{14}{Subfigure 10(b)\relax }{subfigure.10.2}{}}
\newlabel{fig:accrelu}{{10(c)}{14}{Subfigure 10(c)}{subfigure.10.3}{}}
\newlabel{sub@fig:accrelu}{{(c)}{14}{Subfigure 10(c)\relax }{subfigure.10.3}{}}
\newlabel{fig:accsmaller2}{{10(d)}{14}{Subfigure 10(d)}{subfigure.10.4}{}}
\newlabel{sub@fig:accsmaller2}{{(d)}{14}{Subfigure 10(d)\relax }{subfigure.10.4}{}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces Werte der Genauigkeit nach jeder Epoche f\IeC {\"u}r das CNN mit der Referenzstruktur bei Propagation des ungewichteten Trainings- und Validierungsdatensatzes in \ref  {fig:accequal} und bei Propagation des gewichteten Trainings- und Validierungsdatensatzes in \ref  {fig:accnormal} sowie die entsprechenden Werte f\IeC {\"u}r die Verwendung der relu Funktion als Aktivierungsfunktion der versteckten Lagen in \ref  {fig:accrelu} und bei Anpassung der Dimension der dichten Lagen in \ref  {fig:accsmaller2}.\relax }}{14}{figure.10}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {Ungewichteter Datensatz}}}{14}{figure.11}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {Gewichteter Datensatz}}}{14}{figure.11}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {subfigure}{\numberline{(c)}{\ignorespaces {relu statt elu als Aktivierungsfunktion}}}{14}{figure.11}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {subfigure}{\numberline{(d)}{\ignorespaces {Verkleinerte Dimensionen der dichten Lagen}}}{14}{figure.11}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {Ungewichteter Datensatz}}}{14}{figure.12}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {Gewichteter Datensatz}}}{14}{figure.12}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {subfigure}{\numberline{(c)}{\ignorespaces {relu statt elu als Aktivierungsfunktion}}}{14}{figure.12}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {subfigure}{\numberline{(d)}{\ignorespaces {Verkleinerte Dimensionen der dichten Lagen}}}{14}{figure.12}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {Ungewichteter Datensatz}}}{14}{figure.13}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {Gewichteter Datensatz}}}{14}{figure.13}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {subfigure}{\numberline{(c)}{\ignorespaces {relu statt elu als Aktivierungsfunktion}}}{14}{figure.13}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {subfigure}{\numberline{(d)}{\ignorespaces {Verkleinerte Dimensionen der dichten Lagen}}}{14}{figure.13}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {Ungewichteter Datensatz}}}{14}{figure.14}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {Gewichteter Datensatz}}}{14}{figure.14}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {subfigure}{\numberline{(c)}{\ignorespaces {relu statt elu als Aktivierungsfunktion}}}{14}{figure.14}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {subfigure}{\numberline{(d)}{\ignorespaces {Verkleinerte Dimensionen der dichten Lagen}}}{14}{figure.14}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {Ungewichteter Datensatz}}}{14}{figure.15}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {Gewichteter Datensatz}}}{14}{figure.15}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {subfigure}{\numberline{(c)}{\ignorespaces {relu statt elu als Aktivierungsfunktion}}}{14}{figure.15}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {subfigure}{\numberline{(d)}{\ignorespaces {Verkleinerte Dimensionen der dichten Lagen}}}{14}{figure.15}}
\newlabel{fig:lossequal}{{11(a)}{15}{Subfigure 11(a)}{subfigure.11.1}{}}
\newlabel{sub@fig:lossequal}{{(a)}{15}{Subfigure 11(a)\relax }{subfigure.11.1}{}}
\newlabel{fig:lossnormal}{{11(b)}{15}{Subfigure 11(b)}{subfigure.11.2}{}}
\newlabel{sub@fig:lossnormal}{{(b)}{15}{Subfigure 11(b)\relax }{subfigure.11.2}{}}
\newlabel{fig:lossrelu}{{11(c)}{15}{Subfigure 11(c)}{subfigure.11.3}{}}
\newlabel{sub@fig:lossrelu}{{(c)}{15}{Subfigure 11(c)\relax }{subfigure.11.3}{}}
\newlabel{fig:losssmaller2}{{11(d)}{15}{Subfigure 11(d)}{subfigure.11.4}{}}
\newlabel{sub@fig:losssmaller2}{{(d)}{15}{Subfigure 11(d)\relax }{subfigure.11.4}{}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces Werte der Verlustfunktion nach jeder Epoche f\IeC {\"u}r das CNN mit der Referenzstruktur bei Propagation des ungewichteten Trainings- und Validierungsdatensatzes in \ref  {fig:lossequal} und bei Propagation des gewichteten Trainings- und Validierungsdatensatzes in \ref  {fig:lossnormal} sowie die entsprechenden Werte f\IeC {\"u}r die Verwendung der relu Funktion als Aktivierungsfunktion der versteckten Lagen in \ref  {fig:lossrelu} und bei Anpassung der Dimension der dichten Lagen in \ref  {fig:losssmaller2}.\relax }}{15}{figure.11}}
\newlabel{fig:NORMALequal}{{12(a)}{16}{Subfigure 12(a)}{subfigure.12.1}{}}
\newlabel{sub@fig:NORMALequal}{{(a)}{16}{Subfigure 12(a)\relax }{subfigure.12.1}{}}
\newlabel{fig:NORMALnormal}{{12(b)}{16}{Subfigure 12(b)}{subfigure.12.2}{}}
\newlabel{sub@fig:NORMALnormal}{{(b)}{16}{Subfigure 12(b)\relax }{subfigure.12.2}{}}
\newlabel{fig:NORMALrelu}{{12(c)}{16}{Subfigure 12(c)}{subfigure.12.3}{}}
\newlabel{sub@fig:NORMALrelu}{{(c)}{16}{Subfigure 12(c)\relax }{subfigure.12.3}{}}
\newlabel{fig:NORMALsmaller}{{12(d)}{16}{Subfigure 12(d)}{subfigure.12.4}{}}
\newlabel{sub@fig:NORMALsmaller}{{(d)}{16}{Subfigure 12(d)\relax }{subfigure.12.4}{}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {12}{\ignorespaces Verteilung der von dem CNN vorhergesagten Wahrscheinlichkeiten f\IeC {\"u}r die Aufnahmen der Klasse NORMAL und die Aufnahmen au{\ss }erhalb der Klasse NORMAL (!=NORMAL) der Klasse NORMAL anzugeh\IeC {\"o}ren f\IeC {\"u}r das CNN mit der Referenzstruktur bei Propagation des ungewichteten Trainings- und Validierungsdatensatzes in \ref  {fig:NORMALequal} und bei Propagation des gewichteten Trainings- und Validierungsdatensatzes in \ref  {fig:NORMALnormal} sowie die entsprechenden Werte f\IeC {\"u}r die Verwendung der relu Funktion als Aktivierungsfunktion der versteckten Lagen in \ref  {fig:NORMALrelu} und bei Anpassung der Dimension der dichten Lagen in \ref  {fig:NORMALsmaller}.\relax }}{16}{figure.12}}
\newlabel{fig:CNVequal}{{13(a)}{17}{Subfigure 13(a)}{subfigure.13.1}{}}
\newlabel{sub@fig:CNVequal}{{(a)}{17}{Subfigure 13(a)\relax }{subfigure.13.1}{}}
\newlabel{fig:CNVnormal}{{13(b)}{17}{Subfigure 13(b)}{subfigure.13.2}{}}
\newlabel{sub@fig:CNVnormal}{{(b)}{17}{Subfigure 13(b)\relax }{subfigure.13.2}{}}
\newlabel{fig:CNVrelu}{{13(c)}{17}{Subfigure 13(c)}{subfigure.13.3}{}}
\newlabel{sub@fig:CNVrelu}{{(c)}{17}{Subfigure 13(c)\relax }{subfigure.13.3}{}}
\newlabel{fig:CNVsmaller}{{13(d)}{17}{Subfigure 13(d)}{subfigure.13.4}{}}
\newlabel{sub@fig:CNVsmaller}{{(d)}{17}{Subfigure 13(d)\relax }{subfigure.13.4}{}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {13}{\ignorespaces Verteilung der von dem CNN vorhergesagten Wahrscheinlichkeiten f\IeC {\"u}r die Aufnahmen der Klasse CNV und die Aufnahmen au\IeC {\ss }erhalb der Klasse CNV (!=CNV) der Klasse CNV anzugeh\IeC {\"o}ren f\IeC {\"u}r das CNN mit der Referenzstruktur bei Propagation des ungewichteten Trainings- und Validierungsdatensatzes in \ref  {fig:CNVequal} und bei Propagation des gewichteten Trainings- und Validierungsdatensatzes in \ref  {fig:CNVnormal} sowie die entsprechenden Werte f\IeC {\"u}r die Verwendung der relu Funktion als Aktivierungsfunktion der versteckten Lagen in \ref  {fig:CNVrelu} und bei Anpassung der Dimension der dichten Lagen in \ref  {fig:CNVsmaller}.\relax }}{17}{figure.13}}
\newlabel{fig:DMEequal}{{14(a)}{18}{Subfigure 14(a)}{subfigure.14.1}{}}
\newlabel{sub@fig:DMEequal}{{(a)}{18}{Subfigure 14(a)\relax }{subfigure.14.1}{}}
\newlabel{fig:DMEnormal}{{14(b)}{18}{Subfigure 14(b)}{subfigure.14.2}{}}
\newlabel{sub@fig:DMEnormal}{{(b)}{18}{Subfigure 14(b)\relax }{subfigure.14.2}{}}
\newlabel{fig:DMErelu}{{14(c)}{18}{Subfigure 14(c)}{subfigure.14.3}{}}
\newlabel{sub@fig:DMErelu}{{(c)}{18}{Subfigure 14(c)\relax }{subfigure.14.3}{}}
\newlabel{fig:DMEsmaller}{{14(d)}{18}{Subfigure 14(d)}{subfigure.14.4}{}}
\newlabel{sub@fig:DMEsmaller}{{(d)}{18}{Subfigure 14(d)\relax }{subfigure.14.4}{}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {14}{\ignorespaces Verteilung der von dem CNN vorhergesagten Wahrscheinlichkeiten f\IeC {\"u}r die Aufnahmen der Klasse DME und die Aufnahmen au\IeC {\ss }erhalb der Klasse DME (!=DME) der Klasse DME anzugeh\IeC {\"o}ren f\IeC {\"u}r das CNN mit der Referenzstruktur bei Propagation des ungewichteten Trainings- und Validierungsdatensatzes in \ref  {fig:DMEequal} und bei Propagation des gewichteten Trainings- und Validierungsdatensatzes in \ref  {fig:DMEnormal} sowie die entsprechenden Werte f\IeC {\"u}r die Verwendung der relu Funktion als Aktivierungsfunktion der versteckten Lagen in \ref  {fig:DMErelu} und bei Anpassung der Dimension der dichten Lagen in \ref  {fig:DMEsmaller}.\relax }}{18}{figure.14}}
\newlabel{fig:DRUSENequal}{{15(a)}{19}{Subfigure 15(a)}{subfigure.15.1}{}}
\newlabel{sub@fig:DRUSENequal}{{(a)}{19}{Subfigure 15(a)\relax }{subfigure.15.1}{}}
\newlabel{fig:DRUSENnormal}{{15(b)}{19}{Subfigure 15(b)}{subfigure.15.2}{}}
\newlabel{sub@fig:DRUSENnormal}{{(b)}{19}{Subfigure 15(b)\relax }{subfigure.15.2}{}}
\newlabel{fig:DRUSENrelu}{{15(c)}{19}{Subfigure 15(c)}{subfigure.15.3}{}}
\newlabel{sub@fig:DRUSENrelu}{{(c)}{19}{Subfigure 15(c)\relax }{subfigure.15.3}{}}
\newlabel{fig:DRUSENsmaller}{{15(d)}{19}{Subfigure 15(d)}{subfigure.15.4}{}}
\newlabel{sub@fig:DRUSENsmaller}{{(d)}{19}{Subfigure 15(d)\relax }{subfigure.15.4}{}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {15}{\ignorespaces Verteilung der von dem CNN vorhergesagten Wahrscheinlichkeiten f\IeC {\"u}r die Aufnahmen der Klasse DRUSEN und die Aufnahmen au\IeC {\ss }erhalb der Klasse DRUSEN (!=DRUSEN) der Klasse DRUSEN anzugeh\IeC {\"o}ren f\IeC {\"u}r das CNN mit der Referenzstruktur bei Propagation des ungewichteten Trainings- und Validierungsdatensatzes in \ref  {fig:DRUSENequal} und bei Propagation des gewichteten Trainings- und Validierungsdatensatzes in \ref  {fig:DRUSENnormal} sowie die entsprechenden Werte f\IeC {\"u}r die Verwendung der relu Funktion als Aktivierungsfunktion der versteckten Lagen in \ref  {fig:DRUSENrelu} und bei Anpassung der Dimension der dichten Lagen in \ref  {fig:DRUSENsmaller}.\relax }}{19}{figure.15}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {B}Zusatzliche Abbildungen und Ergebnisse zur Optimierungsstudie des DNN}{20}{appendix.B}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {Genauigkeit}}}{20}{figure.16}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {Verlustfunktion}}}{20}{figure.16}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {subfigure}{\numberline{(c)}{\ignorespaces {Genauigkeit}}}{20}{figure.16}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {subfigure}{\numberline{(d)}{\ignorespaces {Verlustfunktion}}}{20}{figure.16}}
\newlabel{fig:testnorm}{{16(a)}{20}{Subfigure 16(a)}{subfigure.16.1}{}}
\newlabel{sub@fig:testnorm}{{(a)}{20}{Subfigure 16(a)\relax }{subfigure.16.1}{}}
\newlabel{fig:testcnv}{{16(b)}{20}{Subfigure 16(b)}{subfigure.16.2}{}}
\newlabel{sub@fig:testcnv}{{(b)}{20}{Subfigure 16(b)\relax }{subfigure.16.2}{}}
\newlabel{fig:testdme}{{16(c)}{20}{Subfigure 16(c)}{subfigure.16.3}{}}
\newlabel{sub@fig:testdme}{{(c)}{20}{Subfigure 16(c)\relax }{subfigure.16.3}{}}
\newlabel{fig:testdrusen}{{16(d)}{20}{Subfigure 16(d)}{subfigure.16.4}{}}
\newlabel{sub@fig:testdrusen}{{(d)}{20}{Subfigure 16(d)\relax }{subfigure.16.4}{}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {16}{\ignorespaces Verteilung der von dem CNN vorhergesagten Wahrscheinlichkeiten unter Verwendung des Testdatensatzes f\IeC {\"u}r die Aufnahmen innerhalb einer Klasse X und f\IeC {\"u}r die Aufnahmen, die nicht dieser Klasse angeh\IeC {\"o}ren (!=X), der Klasse X anzugeh\IeC {\"o}ren. Die Abbildungen \ref  {fig:testnorm}, \ref  {fig:testcnv}, \ref  {fig:testdme} und \ref  {fig:testdrusen} zeigen dies f\IeC {\"u}r die Klassen NORMAL, CNV, DME respektive DRUSEN.\relax }}{20}{figure.16}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {Genauigkeit}}}{20}{figure.17}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {Verlustfunktion}}}{20}{figure.17}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {subfigure}{\numberline{(c)}{\ignorespaces {Genauigkeit}}}{20}{figure.17}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {subfigure}{\numberline{(d)}{\ignorespaces {Verlustfunktion}}}{20}{figure.17}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {Normal}}}{20}{figure.18}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {Normal}}}{20}{figure.18}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {subfigure}{\numberline{(c)}{\ignorespaces {CNV}}}{20}{figure.18}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {subfigure}{\numberline{(d)}{\ignorespaces {CNV}}}{20}{figure.18}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {subfigure}{\numberline{(e)}{\ignorespaces {DME}}}{20}{figure.18}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {subfigure}{\numberline{(f)}{\ignorespaces {DME}}}{20}{figure.18}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {subfigure}{\numberline{(g)}{\ignorespaces {DRUSEN}}}{20}{figure.18}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {subfigure}{\numberline{(h)}{\ignorespaces {DRUSEN}}}{20}{figure.18}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {Modell 0}}}{20}{figure.19}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {Modell 1}}}{20}{figure.19}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {subfigure}{\numberline{(c)}{\ignorespaces {Modell 2}}}{20}{figure.19}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {subfigure}{\numberline{(d)}{\ignorespaces {Modell 3}}}{20}{figure.19}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {subfigure}{\numberline{(e)}{\ignorespaces {Modell 4}}}{20}{figure.19}}
\newlabel{fig:valnorm}{{17(a)}{21}{Subfigure 17(a)}{subfigure.17.1}{}}
\newlabel{sub@fig:valnorm}{{(a)}{21}{Subfigure 17(a)\relax }{subfigure.17.1}{}}
\newlabel{fig:valcnv}{{17(b)}{21}{Subfigure 17(b)}{subfigure.17.2}{}}
\newlabel{sub@fig:valcnv}{{(b)}{21}{Subfigure 17(b)\relax }{subfigure.17.2}{}}
\newlabel{fig:valdme}{{17(c)}{21}{Subfigure 17(c)}{subfigure.17.3}{}}
\newlabel{sub@fig:valdme}{{(c)}{21}{Subfigure 17(c)\relax }{subfigure.17.3}{}}
\newlabel{fig:valdrusen}{{17(d)}{21}{Subfigure 17(d)}{subfigure.17.4}{}}
\newlabel{sub@fig:valdrusen}{{(d)}{21}{Subfigure 17(d)\relax }{subfigure.17.4}{}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {17}{\ignorespaces Verteilung der von dem CNN vorhergesagten Wahrscheinlichkeiten unter Verwendung des Validierungsdatensatzes f\IeC {\"u}r die Aufnahmen innerhalb einer Klasse X und f\IeC {\"u}r die Aufnahmen, die nicht dieser Klasse angeh\IeC {\"o}ren (!=X), der Klasse X anzugeh\IeC {\"o}ren. Die Abbildungen \ref  {fig:valnorm}, \ref  {fig:valcnv}, \ref  {fig:valdme} und \ref  {fig:valdrusen} zeigen dies f\IeC {\"u}r die Klassen NORMAL, CNV, DME respektive DRUSEN.\relax }}{21}{figure.17}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {18}{\ignorespaces Beispielbilder f\IeC {\"u}r jede der Klassen im $(50,\tmspace  +\thinmuskip {.1667em}100)$ Format (links) sowie die aus der Abrasterung durch $(2,\tmspace  +\thinmuskip {.1667em}4)$ Fenster erhaltene Verteilung der Mittelwerte (rechts).\relax }}{22}{figure.18}}
\newlabel{fig:input}{{18}{22}{Beispielbilder f체r jede der Klassen im $(50,\,100)$ Format (links) sowie die aus der Abrasterung durch $(2,\,4)$ Fenster erhaltene Verteilung der Mittelwerte (rechts).\relax }{figure.18}{}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {19}{\ignorespaces Erhaltene Werte der Verlustfunktion des DNN f\IeC {\"u}r die verschiedenen Konfigurationen der einzelnen Modelle als Funktion der Batch Gr\IeC {\"o}{\ss }e.\relax }}{23}{figure.19}}
\newlabel{fig:lossgrid}{{19}{23}{Erhaltene Werte der Verlustfunktion des DNN f체r die verschiedenen Konfigurationen der einzelnen Modelle als Funktion der Batch Gr철{\ss }e.\relax }{figure.19}{}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {20}{\ignorespaces Verwirrungsmatrix bei Propagation des Valdierungsdatensatzes f\IeC {\"u}r die gew\IeC {\"a}hlte DNN Struktur.\relax }}{23}{figure.20}}
\global\@altsecnumformattrue
