\subsection{Tiefes flaches neuronales Netz (DNN)}

Um die Wahl des CNN zu validieren wird diese mit einer alternativen Methode verglichen. Diese basiert auf einem flachen tiefen neuronalen Netz (DNN), welches aus vollständig vernetzten dichten Lagen besteht. \\
Hierzu müssen die zu analysierenden Aufnahmen zunächst in eine eindimensionale Liste aus Werten umgewandelt werden. Dabei muss beachtet werden, dass diese Liste nicht zu gro{\ss} wird, da ansonsten das Training und die Optimierung des neuronalen Netzes zu zeitaufwendig ist. Demnach wird die Dimension der Aufnahmen auf $(50\times 100)$ reduziert.\\
In ersten Studien auf einem kleineren Datensatz erweist es sich als vielversprechend die Dimension der Aufnahmen weiter zu verringern. Hierzu wird ein Fenster der Dimension $(2\times 4)$ definiert, welches die Aufnahmen ohne Überlappung der einzelnen Schritte abrastert und den Mittelwert der im Fenster liegenden Pixelwerte in jedem Schritt berechnet. Anschlie{\ss}end werden die so erhaltenen 625 Mittelwerte auf den grö{\ss}ten Mittelwert einer Aufnahme skaliert und dem DNN als eindimensionale Liste übergeben. In den ersten Studien zeigte sich bei dieser Methode eine Genauigkeit von $70\,\%$ und gröbere Körnungen der Aufnahmen sowie andere Fenstergrö{\ss}en lieferten keine Verbesserungen, wodurch diese Methodik vielversprechend erscheint und im Folgenden betrachtet wird. \\
% Darauf aufbauend werden drei Verfahren untersucht aus diesen Bilder eine eindimensionale Liste zu erstellen, welche als Eingangseigenschaften des DNN der Aufnahmen verwendet werden. Zum einen werden alle Pixelwerte einer $(50\times 100)$ Aufnahme in eine eindimensionale Liste umgewandelt und dem DNN übergeben. Erste Studien hierzu liefern eine Genauigkeit der Klassifikation von ungefähr $55\,\%$. Die zweite Methode basiert darauf für jede $x$- und $y$-Linie der Aufnahme den Mittelwert aller Pixelwerte der jeweiligen Linie zu berechnen. Auch bei dieser Methodik wird eine Genauigkeit von ungefähr $55\,\%$ erzielt. Die letzte Methode basiert darauf das Bild weiter zu verkleinern, indem ein Fenster der Dimension $(2\times 4)$ definiert wird, welches die Aufnahmen abrastert, wobei keine Überlappung der einzelnen Schritte entsteht. Der Mittelwert der im Fenster liegenden Pixel wird für jeden Schritt der Abrasterung berechnet. Anschlie{\ss}end werden die so erhaltenen 625 Mittelwerte auf den grö{\ss}ten Mittelwert einer Aufnahme skaliert und dem DNN übergeben. In den vereinfachten ersten Studien zeigte sich bei dieser Methode eine Genauigkeit von $70\,\%$, wodurch diese vielversprechend erscheint und im Folgenden betrachtet wird. \\
% Abbildung \ref{fig:input} zeigt beispielhaft für jede der Klassen das $(50,\,100)$ Bild sowie die aus dem resultierende Verteilung der Mittelwerte. Die gewählten Beispiele sind so ausgewählt worden, dass anhand der Aufnahmen bereits per Auge eine Entscheidung getroffen werden kann, sodass dies den Fall representiert bei dem eine Klassifizierung der Bilder sehr gut möglich ist. Das ist jedoch nicht bei allen  Bildern der Fall. Ein Blick auf die Verteilungen der Mittelwerte lässt bereits den Schluss zu, dass CNV die Klasse darstellt, die am besten von den anderen zu trennen ist. Es ist au{\ss}erdem zu erwarten, dass sich DRUSEN von NORMAL schwer unterscheiden lässt. \\
Um eine geeignete Referenzstruktur des DNN zu finden mit der das CNN verglichen werden kann, werden verschiedene Netzstrukturen getestet. Es werden 5 Grundstrukturen des DNN definiert, welche in Tabelle \ref{tab:DNNstruk} dargestellt sind und als Modell $i$ ($i = 0,\,1,\,2,\,3,\,4$) bezeichnet werden. Dabei folgt auf jede versteckte Lage eine Dropout Lage, wobei die Anzahl an Ausgangsneuronen beziehungsweise die verwendete Dropout Rate der $j$-ten Lage durch das $j$-te Element in den entsprechenden Listen in Tabelle \ref{tab:DNNstruk} dargestellt sind. \\
\captionsetup[table]{name=Tabelle}
\begin{table}[!b]
\centering
\caption{Getestete Grundstrukturen des DNN. Die Anzahl an Neuronen in der $i$-ten versteckten Lage und die Dropout Rate in der $i$-ten Dropout Lage sind durch das $i$-te Element der entsprechenden List dargestellt. Auf die $i$-te versteckte Lage folgt dabei die $i$-te Dropout Lage.}
\label{tab:DNNstruk}
 \begin{tabular}{c|c|c}
 & Struktur der versteckten dichten Lagen & Struktur der Dropout Lagen \\
 \hline
 Modell 0 & (1024, 512, 128, 64, 32) & (0.5, 0.4, 0.4, 0.3, 0.2) \\
 Modell 1 & (1024, 512, 256, 128, 64, 32, 16) & (0.5, 0.4, 0.4, 0.4, 0.2, 0.2, 0.1)\\
 Modell 2 & (512, 256, 128, 64, 32, 16) & (0.4, 0.4, 0.3, 0.3, 0.2, 0.1)\\
 Modell 3 & (1024, 256, 64, 16) & (0.6, 0.4, 0.2, 0.1)\\
 Modell 4 & (512, 128, 32) &  (0.5, 0.3, 0.1)\\
 \end{tabular}
\end{table}
Für jede der fünf Grundstrukturen werden die Aktivierungsfunktionen elu und relu sowie softmax und sigmoid für die versteckten Lage respektive für die Ausgangslage getestet. Zudem werden die Batch Grö{\ss}en 50, 100, 128, 256 und 512 für jede der sich ergebenden DNN Konfigurationen eingestellt. Insgesamt werden somit 120 Konfigurationen für das Training des DNN überprüft. \\
Als Verlustfunktion wird wie beim CNN die kategorische Kreuzentropie verwendet und als Metrik die Genauigkeit betrachtet. Der Adam Optimierer wird hierbei mit einer angepassten Lernrate von 0.0001 benutzt. Der Datensatz wird in den Trainings-, Validierungs- und Testdatensatz aufgeteilt, die aus $67,5\,\%$, $25\,\%$ respektive $7,5\,\%$ des kompletten Datensatzes bestehen. Die verschiedenen Konfigurationen werden jeweils 150 Epochen lang trainiert. Die Werte der Genauigkeit bei Propagation des Validierungsdatensatzes als Funktion der Batch Grö{\ss}e ist für jede Konfiguration eines Modells in Abbildung \ref{fig:accgrid} dargestellt.\\
\begin{figure}[!t]
 \centering
\begin{subfigure}[Modell 0]{
\includegraphics[width=.30\linewidth]{fig/Modelvalacc0.pdf}}
\end{subfigure}%
\begin{subfigure}[Modell 1]{
\includegraphics[width=.30\linewidth]{fig/Modelvalacc1.pdf}}
\end{subfigure}
\begin{subfigure}[Modell 2]{
\includegraphics[width=.30\linewidth]{fig/Modelvalacc2.pdf}}
\end{subfigure}\\
\begin{subfigure}[Modell 3]{
\includegraphics[width=.30\linewidth]{fig/Modelvalacc3.pdf}}
\end{subfigure}
\begin{subfigure}[Modell 4]{
\includegraphics[width=.30\linewidth]{fig/Modelvalacc4.pdf}}
\end{subfigure}
\caption{Erhaltene Genauigkeiten des DNN für die verschiedenen Konfigurationen der einzelnen Modelle als Funktion der Batch Grö{\ss}e.}
\label{fig:accgrid}
\end{figure}
\setcounter{subfigure}{0}
Um ungeeignete DNN Konfigurationen herauszufiltern werden zwei verschiedene Kriterien definiert, die von den Konfigurationen erfüllt werden müssen. Zum einen muss die Genauigkeit auf dem Validierungsdatensatz grö{\ss}er als $73\,\%$ sein. Das zweite Kriterium filtert Konfigurationen heraus, die ein starkes Übertraining aufweisen, indem gefordert wird, dass der Wert der Verlustfunktion nach der ersten Epoche um mindestens $5\,\%$ nach der letzten Epoche gesunken ist. Nach der Anwendung dieser Selektionskriterien verbleiben 12 DNN Konfigurationen. Es stellt sich hierbei vor allem heraus, dass hohe Batch Grö{\ss}en ungeeignet sind, da keine der Konfigurationen mit einer Batch Grö{\ss}e von 512 und nur eine Konfiguration mit einer Batch Grö{\ss}e von 256 die Selektionsschritte passieren. Um die optimale Konfiguration zu wählen, wird die Gesamtgenauigkeit wie im Falle des CNN berechnet und das Maximum gesucht. Dieses ergibt sich für das Modell 0 unter Verwendung der relu Funktion und der sigmoid Funktion als Aktivierungsfunktion der versteckten Lagen respektive der Ausgangslage bei einer Batch Grö{\ss}e von 50 und beträgt $72\,\%$ auf dem Validierungsdatensatz. Die Werte der Verlustfunktion nach jeder Epoche sind für dieses Modell in Abbildung \ref{fig:DNNloss} dargestellt. \\
% \begin{figure}[!t]
% \centering
%  \includegraphics[width=.45\linewidth]{fig/confusionmatrix6test.pdf}
%  \caption{Verwirrungsmatrix der gewählten DNN Konfiguration ermittelt auf dem Trainingsdatensatz.}
%  \label{fig:ConfmatDNN}
% \end{figure}
Anhand Abbildung \ref{fig:DNN} ist zudem ersichtlich, dass kein signifikantes Übertraining vorhanden ist und die Genauigkeit bereits einen Sättigungswert erreicht hat. In Abbildung \ref{fig:confmatDNN} ist die entsprechende Verwirrungsmatrix dargestellt, welche auf dem Testdatensatz ermittelt wird. Auch hier errechnet sich eine Gesamtgenauigkeit von $72\,\%$, wodurch bestätigt wird, dass das DNN eine geeignete Struktur aufweist, die kein starkes Übertraining besitzt. 
\begin{figure}[!b]
 \centering
%    \begin{subfigure}[Genauigkeit]{
%  \includegraphics[width=.40\linewidth]{fig/accuracyhistory6.pdf}\label{fig:DNNacc}}
%   \end{subfigure}
 \begin{subfigure}[Verlustfunktion]{
 \includegraphics[width=.45\linewidth]{fig/losshistory6.pdf}\label{fig:DNNloss}}
  \end{subfigure}
  \begin{subfigure}[Verwirrungsmatrix]{
  \includegraphics[width=.35\linewidth]{fig/confusionmatrix6test.pdf}\label{fig:confmatDNN}}
  \end{subfigure}
  \caption{Wert der Verlustfunktion nach jeder Epoche \ref{fig:DNNloss} bei Propagation des Trainings- und Validierungsdatensatzes und Verwirrungsmatrix \ref{fig:confmatDNN} bei Propagation des Testdatensatzes für die gewählte DNN Struktur. }
  \label{fig:DNN}
\end{figure}
\setcounter{subfigure}{0}












